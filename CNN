# for pytorch
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import torch.nn.functional as F
import torchvision.models as models
from torch.optim.lr_scheduler import ExponentialLR

# Check if CUDA is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define data transformations (optional, but recommended)(Standard Normalization)
transform = transforms.Compose([transforms.ToTensor() ,transforms.Normalize ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])

# Load the training dataset
train_dataset = torchvision.datasets.CIFAR10(root ='./data ', train = True, transform = transform, download = True)

# Load the testing dataset
test_dataset = torchvision . datasets . CIFAR10 ( root ='./data ', train = False , transform = transform , download = True )

class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3)    #No of fiters 32 , kernal size 3*3
        self.pool1 = nn.MaxPool2d(2, 2)  #pooling 2*2 with stride 2
        self.conv2 = nn.Conv2d(32, 128*2, 3)   # No of filters 128 , kernal size 3*3
        self.pool2 = nn.MaxPool2d(2, 2)  #pooling 2*2 with stride 2
        self.fc1 = nn.Linear(128*2*6*6, 256) #intermdediate layer with 256 layer
        self.fc2 = nn.Linear(256, 10)  # 10 output classes

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(-1, 128*2*6*6)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.fc2(x)
        return x

# Initialize the model
model = CNNModel()
# Assuming you have a training dataset and a validation dataset
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)
